{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Youtube.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1TdcTubyDq4I7q53MmVOZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/homembit/AI_Tutorials/blob/main/MNIST_Youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mib6NrVSQSYs"
      },
      "source": [
        "# **MNIST - O Hello World de AI :)**\n",
        "\n",
        "Uma boa visualização do que vamos fazer, interativa pode ser encontrada nesse site\n",
        "http://scs.ryerson.ca/~aharley/vis/conv/\n",
        "\n",
        "A topologia básica da rede que vamos montar é a [LeNet](https://en.wikipedia.org/wiki/LeNet), e pode ser simplificada assim:\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHzoyOOW7Hps"
      },
      "source": [
        "# Montar nossa CNN e realizar o treinamento\n",
        "\n",
        "O Keras pode importar muitas topologias prontas, mas vamos construir essa na mão.\n",
        "\n",
        "Iniciamos importando um modelo de rede neural [sequencial](https://keras.io/models/sequential/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYkD95lhprmk"
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCIe7uROpvsV"
      },
      "source": [
        "Documentação das camadas principais do Keras https://keras.io/layers/core/\n",
        "\n",
        "> **Dense**: Vamos usar uma camada densa como camada de classificação\n",
        "> \n",
        "> **Flatten**: Camada para transformar matriz em vetor\n",
        "> \n",
        "> **Dropout**: Camada para descartar aleatoriamente uma parte dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrWWuoxTpzKk"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Dropout"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "try6kp9KqLo5"
      },
      "source": [
        "Documentação das camadas de convolução https://keras.io/layers/convolutional/\n",
        "> **Conv2D**: Camada de convolução de imagens em 2D (nossas imagens com os digitos de entrada, vindo do nosso dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFKRK1agqMmf"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwcOjRJvtYwt"
      },
      "source": [
        "Documentação da camada de Pooling: https://keras.io/layers/pooling/\n",
        "> **MaxPooling2D**: Camada para reduzir as matrizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-PzS7TqtX85"
      },
      "source": [
        "from tensorflow.keras.layers import MaxPooling2D"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9qHGoGPtgWx"
      },
      "source": [
        "Funções de utilitários do Keras https://keras.io/utils/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_qEq-gMtgeD"
      },
      "source": [
        "from tensorflow.keras import utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1quPi1wtu0j"
      },
      "source": [
        "Dataset do MNIST https://keras.io/datasets/\n",
        "Este Dataset tem 60.000 imagens de 28x28 pixels de numeros de 0-9 para treinamento com mais 10.000 imagens para testes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjt3Y7vJtvG3"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAgJyZpmt5jg"
      },
      "source": [
        "Otimizador Adam para a descida do gradiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH6jGS7ut51U"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA05fz4muAmd"
      },
      "source": [
        "Call backs do Keras para a otimização do treinamento\n",
        ">**ModelCheckpoint**: Grava cada modelo treinado que a obedeça um critério específico\n",
        ">\n",
        ">**EarlyStopping**: Interrompe o treinamento quando um critério é atendido\n",
        ">\n",
        ">**ReduceLROnPlateau**: Reduz o Learning Rate quando está próximo de um ponto de mínimo\n",
        ">\n",
        ">**TensorBoard**: Gera dados para análise e acompanhamento do treinamento no TensoBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddEGXdKsuAz6"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1STWbzCAveUn"
      },
      "source": [
        "Carrega o DataSet do MNIST data em dois conjuntos: Treinamento (60K imagens) e Testes (10k imagens)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH_EGKP5vekL",
        "outputId": "c753243f-466a-4a64-fb1b-e713907bc0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(train_dataset, train_classes),(test_dataset, test_classes) = mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaxZJ90GvlL_"
      },
      "source": [
        "Ajusta os datasets para o TensorFlow, reduzindo os canais de imagens de 3 para 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esymfr9vvlXB"
      },
      "source": [
        "train_dataset = train_dataset.reshape(train_dataset.shape[0], 28, 28, 1)\n",
        "test_dataset = test_dataset.reshape(test_dataset.shape[0], 28, 28, 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCQYWyE0wIZg"
      },
      "source": [
        "Converte os dados de int8 para float32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hakH5MANwIib"
      },
      "source": [
        "train_dataset = train_dataset.astype('float32')\n",
        "test_dataset = test_dataset.astype('float32')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGgJ5WnFwNYF"
      },
      "source": [
        "Normaliza os dados para acelerar o processamento, reduzindo o tamanho dos números"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61WZr93XwNgV"
      },
      "source": [
        "train_dataset = train_dataset / 255\n",
        "test_dataset = test_dataset / 255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFKFxebFwbGn"
      },
      "source": [
        "Converte as classes de dados de numérica para categorias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIe6Z0kqwbQv"
      },
      "source": [
        "train_classes = utils.to_categorical(train_classes, 10)\n",
        "test_classes = utils.to_categorical(test_classes, 10)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ObTPXhlwhX3"
      },
      "source": [
        "Cria a Rede Neural Convolucional (Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eM_QmtKwhkI"
      },
      "source": [
        "cnn = Sequential()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ninlynpBwl3P"
      },
      "source": [
        "Adiciona a primeira camada convolucional com 32 filtros e uma janela de convolução de 3x3, com a matriz de entrada com imagens de 28 x 28 pixels (1 canal de cores) e usando ativação ReLu ([Rectified Linear Unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmJMV0KXwmCa"
      },
      "source": [
        "cnn.add(Conv2D(32, (3,3), input_shape = (28, 28, 1), activation = 'relu'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTsXer-OyHDv"
      },
      "source": [
        "Reduz o tamanho das matrizes de convolução"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAcFWF6fyHM-"
      },
      "source": [
        "cnn.add(MaxPooling2D())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MmcH1A5yOZR"
      },
      "source": [
        "Descarta aleatoriamente 25% das imagens\n",
        "\n",
        "**NOTA:** Altere esse percentual e observe a diferença na acurácia :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMQ99iOlyOh5"
      },
      "source": [
        "cnn.add(Dropout(0.25))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrVcDBcSyXhV"
      },
      "source": [
        "Transforma a matriz de saída em um vetor para ser processado pela rede neural\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TurmpZxyyXp_"
      },
      "source": [
        "cnn.add(Flatten())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksZVyRonyece"
      },
      "source": [
        "Primeira camada da rede neural, uma camada oculta com 128 neurônios e usando ReLu como ativação "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY5AGUXNyepF"
      },
      "source": [
        "cnn.add(Dense(units = 128, activation = 'relu'))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzKYJLADykRz"
      },
      "source": [
        "Descarta aleatoriamente 50% dos resultados\n",
        "\n",
        "**NOTA:** Altere esse percentual e observe a diferença na acurácia :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPZtJPE3ykvx"
      },
      "source": [
        "cnn.add(Dropout(0.5))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU3Llo8tyrjk"
      },
      "source": [
        "**NOTA:** Como exercício aqui, incluir mais camadas ocultas e observar os resultados no tempo de treinamento vs acurácia.\n",
        "\n",
        "Camada de saída com 10 neurônios (um para cada camanda) usando Softmax como função de ativação, dada a natureza do problema matemático"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGlEhGxOyrsO"
      },
      "source": [
        "cnn.add(Dense(units = 10, activation = 'softmax'))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RnbECNsy6dK"
      },
      "source": [
        "Compilar a CNN com:\n",
        ">- [Categorical crossentropy](https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class) como função de perda\n",
        ">- Otimizador [Adam](https://keras.io/api/optimizers/adam/) \n",
        ">- Acurácia como métrica de avaliação (Loss pode ser usado também.. pesquise sobre [Overfitting](https://en.wikipedia.org/wiki/Overfitting) para entender)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sk1iZ8qy6nb"
      },
      "source": [
        "adam = Adam(lr=0.001)\n",
        "cnn.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3beqj_szDIv"
      },
      "source": [
        "Setup dos callbacks:\n",
        "\n",
        "Nome do arquivo para o o [ModelCheckPoint](https://keras.io/api/callbacks/model_checkpoint/), um callback que grava os pesos da rede a cada ciclo de treinamento, baseado em critérios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-0MHqH3zDTR"
      },
      "source": [
        "top_layers_file_path=\"MNIST_Model.iv3.hdf5\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff00oNmqzNxh"
      },
      "source": [
        "Monitorar a loss function e salvar cada vez que ela for menor que a anterior\n",
        "otimiza o treinamento para encontrar o ponto de mínima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRBRcrzxzN7c"
      },
      "source": [
        "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW5N2Lhwzp8k"
      },
      "source": [
        "O [EarlyStopping](https://keras.io/api/callbacks/early_stopping/) informa quantas vezes ele deve tentar reduzir o valor da loss funcion \n",
        "antes de interromper o treinamento. Interessante notar o nome do parâmetro do número de vezes: patience :)\n",
        "\n",
        "**Dica**: Aqui falamos pro Keras  que monitore a loss function, pelo mínimo até que ele não diminua em 5 vezes... como gravamos o checkpoint em cada redução no callback anterior... teremos a melhor versão da rede gravada em disco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rWa4hiqztzd"
      },
      "source": [
        "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=30)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE985EZXz-LY"
      },
      "source": [
        "Gera os dados para a análise do treinamento no [TensorBoard](https://keras.io/api/callbacks/tensorboard/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG-wApUOzqG3",
        "outputId": "3e4d051c-e474-4fd1-cc3f-4d228f18c9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tb = TensorBoard(log_dir='./logs', batch_size=128, write_graph=True, update_freq='batch')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELAJP3jo2ttN"
      },
      "source": [
        "Pedimos pro Keras reduzir o Learning Rate quando estiver perto de um ponto de\n",
        "mínima... it's magic :) ... não... é matemática mesmo :P"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGmSjDnR2t3J"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=10, min_lr=0.0001)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQmYz5oK25lz"
      },
      "source": [
        "Executa o treinamento da rede em 50 épocas, validando o resultado com o dataset\n",
        "de treinamento em cada época...\n",
        "\n",
        "**Dica:** Aumente o número de épocas para um número maior, e os dois callbacks que ajustamos anteriormente devem salvar seu cartão de crédito  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLJxvNMJ25wF",
        "outputId": "90b8a3e4-250e-4356-c943-742e8e22a849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnn.fit(train_dataset, train_classes, batch_size = 128, epochs = 300,\n",
        "        validation_data = (test_dataset, test_classes),\n",
        "        callbacks=[checkpoint, early, reduce_lr, tb])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "  1/469 [..............................] - ETA: 0s - loss: 2.3270 - accuracy: 0.0781WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0114s vs `on_train_batch_end` time: 0.0331s). Check your callbacks.\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.9053\n",
            "Epoch 00001: loss improved from inf to 0.32029, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3203 - accuracy: 0.9053 - val_loss: 0.0881 - val_accuracy: 0.9730\n",
            "Epoch 2/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.1250 - accuracy: 0.9633\n",
            "Epoch 00002: loss improved from 0.32029 to 0.12461, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.1246 - accuracy: 0.9633 - val_loss: 0.0633 - val_accuracy: 0.9786\n",
            "Epoch 3/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9717\n",
            "Epoch 00003: loss improved from 0.12461 to 0.09617, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0962 - accuracy: 0.9716 - val_loss: 0.0571 - val_accuracy: 0.9806\n",
            "Epoch 4/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9751\n",
            "Epoch 00004: loss improved from 0.09617 to 0.08324, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0832 - accuracy: 0.9751 - val_loss: 0.0442 - val_accuracy: 0.9842\n",
            "Epoch 5/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9777\n",
            "Epoch 00005: loss improved from 0.08324 to 0.07255, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 0.0439 - val_accuracy: 0.9859\n",
            "Epoch 6/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9802\n",
            "Epoch 00006: loss improved from 0.07255 to 0.06527, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0653 - accuracy: 0.9802 - val_loss: 0.0430 - val_accuracy: 0.9853\n",
            "Epoch 7/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.9811\n",
            "Epoch 00007: loss improved from 0.06527 to 0.05861, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0586 - accuracy: 0.9811 - val_loss: 0.0369 - val_accuracy: 0.9867\n",
            "Epoch 8/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9835\n",
            "Epoch 00008: loss improved from 0.05861 to 0.05127, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0513 - accuracy: 0.9835 - val_loss: 0.0393 - val_accuracy: 0.9864\n",
            "Epoch 9/300\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9839\n",
            "Epoch 00009: loss improved from 0.05127 to 0.05000, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0500 - accuracy: 0.9840 - val_loss: 0.0388 - val_accuracy: 0.9870\n",
            "Epoch 10/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9850\n",
            "Epoch 00010: loss improved from 0.05000 to 0.04613, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.0382 - val_accuracy: 0.9875\n",
            "Epoch 11/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0439 - accuracy: 0.9860\n",
            "Epoch 00011: loss improved from 0.04613 to 0.04382, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 0.0363 - val_accuracy: 0.9875\n",
            "Epoch 12/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9862\n",
            "Epoch 00012: loss improved from 0.04382 to 0.03999, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0400 - accuracy: 0.9862 - val_loss: 0.0342 - val_accuracy: 0.9892\n",
            "Epoch 13/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9882\n",
            "Epoch 00013: loss improved from 0.03999 to 0.03715, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0372 - accuracy: 0.9882 - val_loss: 0.0362 - val_accuracy: 0.9873\n",
            "Epoch 14/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9883\n",
            "Epoch 00014: loss improved from 0.03715 to 0.03592, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 0.0351 - val_accuracy: 0.9884\n",
            "Epoch 15/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0334 - accuracy: 0.9892\n",
            "Epoch 00015: loss improved from 0.03592 to 0.03358, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0345 - val_accuracy: 0.9891\n",
            "Epoch 16/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9893\n",
            "Epoch 00016: loss improved from 0.03358 to 0.03136, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.9893 - val_loss: 0.0390 - val_accuracy: 0.9876\n",
            "Epoch 17/300\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9901\n",
            "Epoch 00017: loss improved from 0.03136 to 0.02894, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0289 - accuracy: 0.9901 - val_loss: 0.0370 - val_accuracy: 0.9886\n",
            "Epoch 18/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9902\n",
            "Epoch 00018: loss improved from 0.02894 to 0.02889, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0289 - accuracy: 0.9902 - val_loss: 0.0355 - val_accuracy: 0.9892\n",
            "Epoch 19/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9907\n",
            "Epoch 00019: loss improved from 0.02889 to 0.02749, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 0.0361 - val_accuracy: 0.9889\n",
            "Epoch 20/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9907\n",
            "Epoch 00020: loss improved from 0.02749 to 0.02604, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0260 - accuracy: 0.9907 - val_loss: 0.0391 - val_accuracy: 0.9879\n",
            "Epoch 21/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9914\n",
            "Epoch 00021: loss improved from 0.02604 to 0.02546, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.0353 - val_accuracy: 0.9895\n",
            "Epoch 22/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9916\n",
            "Epoch 00022: loss improved from 0.02546 to 0.02494, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0249 - accuracy: 0.9916 - val_loss: 0.0364 - val_accuracy: 0.9899\n",
            "Epoch 23/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9926\n",
            "Epoch 00023: loss improved from 0.02494 to 0.02284, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0228 - accuracy: 0.9927 - val_loss: 0.0341 - val_accuracy: 0.9895\n",
            "Epoch 24/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9931\n",
            "Epoch 00024: loss improved from 0.02284 to 0.02097, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0388 - val_accuracy: 0.9892\n",
            "Epoch 25/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9927\n",
            "Epoch 00025: loss did not improve from 0.02097\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0212 - accuracy: 0.9927 - val_loss: 0.0370 - val_accuracy: 0.9892\n",
            "Epoch 26/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9923\n",
            "Epoch 00026: loss did not improve from 0.02097\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9923 - val_loss: 0.0376 - val_accuracy: 0.9886\n",
            "Epoch 27/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9936\n",
            "Epoch 00027: loss improved from 0.02097 to 0.01874, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0403 - val_accuracy: 0.9897\n",
            "Epoch 28/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9932\n",
            "Epoch 00028: loss improved from 0.01874 to 0.01867, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0410 - val_accuracy: 0.9887\n",
            "Epoch 29/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9934\n",
            "Epoch 00029: loss did not improve from 0.01867\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0363 - val_accuracy: 0.9890\n",
            "Epoch 30/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9932\n",
            "Epoch 00030: loss improved from 0.01867 to 0.01825, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.0391 - val_accuracy: 0.9896\n",
            "Epoch 31/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
            "Epoch 00031: loss improved from 0.01825 to 0.01741, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0389 - val_accuracy: 0.9895\n",
            "Epoch 32/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9940\n",
            "Epoch 00032: loss improved from 0.01741 to 0.01644, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 0.0401 - val_accuracy: 0.9887\n",
            "Epoch 33/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9940\n",
            "Epoch 00033: loss did not improve from 0.01644\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0375 - val_accuracy: 0.9894\n",
            "Epoch 34/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9945\n",
            "Epoch 00034: loss did not improve from 0.01644\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0165 - accuracy: 0.9945 - val_loss: 0.0389 - val_accuracy: 0.9904\n",
            "Epoch 35/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9944\n",
            "Epoch 00035: loss improved from 0.01644 to 0.01623, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.0393 - val_accuracy: 0.9898\n",
            "Epoch 36/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9939\n",
            "Epoch 00036: loss did not improve from 0.01623\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0392 - val_accuracy: 0.9898\n",
            "Epoch 37/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9941\n",
            "Epoch 00037: loss improved from 0.01623 to 0.01566, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.0400 - val_accuracy: 0.9901\n",
            "Epoch 38/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9948\n",
            "Epoch 00038: loss improved from 0.01566 to 0.01495, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.0409 - val_accuracy: 0.9894\n",
            "Epoch 39/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9949\n",
            "Epoch 00039: loss improved from 0.01495 to 0.01493, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0380 - val_accuracy: 0.9903\n",
            "Epoch 40/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9946\n",
            "Epoch 00040: loss did not improve from 0.01493\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0404 - val_accuracy: 0.9897\n",
            "Epoch 41/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9952\n",
            "Epoch 00041: loss improved from 0.01493 to 0.01363, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0402 - val_accuracy: 0.9905\n",
            "Epoch 42/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9948\n",
            "Epoch 00042: loss did not improve from 0.01363\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0407 - val_accuracy: 0.9906\n",
            "Epoch 43/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9944\n",
            "Epoch 00043: loss did not improve from 0.01363\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0407 - val_accuracy: 0.9903\n",
            "Epoch 44/300\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9956\n",
            "Epoch 00044: loss improved from 0.01363 to 0.01342, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.0383 - val_accuracy: 0.9903\n",
            "Epoch 45/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9944\n",
            "Epoch 00045: loss did not improve from 0.01342\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.0379 - val_accuracy: 0.9910\n",
            "Epoch 46/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9956\n",
            "Epoch 00046: loss improved from 0.01342 to 0.01279, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0390 - val_accuracy: 0.9900\n",
            "Epoch 47/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9954\n",
            "Epoch 00047: loss did not improve from 0.01279\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.0426 - val_accuracy: 0.9897\n",
            "Epoch 48/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9953\n",
            "Epoch 00048: loss improved from 0.01279 to 0.01260, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 0.0395 - val_accuracy: 0.9904\n",
            "Epoch 49/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9954\n",
            "Epoch 00049: loss did not improve from 0.01260\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0398 - val_accuracy: 0.9909\n",
            "Epoch 50/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9956\n",
            "Epoch 00050: loss did not improve from 0.01260\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0392 - val_accuracy: 0.9901\n",
            "Epoch 51/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9955\n",
            "Epoch 00051: loss did not improve from 0.01260\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0130 - accuracy: 0.9954 - val_loss: 0.0447 - val_accuracy: 0.9894\n",
            "Epoch 52/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9957\n",
            "Epoch 00052: loss improved from 0.01260 to 0.01253, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0402 - val_accuracy: 0.9913\n",
            "Epoch 53/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9960\n",
            "Epoch 00053: loss improved from 0.01253 to 0.01201, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0415 - val_accuracy: 0.9909\n",
            "Epoch 54/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9954\n",
            "Epoch 00054: loss did not improve from 0.01201\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0445 - val_accuracy: 0.9901\n",
            "Epoch 55/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9956\n",
            "Epoch 00055: loss did not improve from 0.01201\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0122 - accuracy: 0.9955 - val_loss: 0.0422 - val_accuracy: 0.9910\n",
            "Epoch 56/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9963\n",
            "Epoch 00056: loss improved from 0.01201 to 0.01058, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0435 - val_accuracy: 0.9909\n",
            "Epoch 57/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9967\n",
            "Epoch 00057: loss improved from 0.01058 to 0.00994, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0495 - val_accuracy: 0.9897\n",
            "Epoch 58/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9958\n",
            "Epoch 00058: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0420 - val_accuracy: 0.9898\n",
            "Epoch 59/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9965\n",
            "Epoch 00059: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0496 - val_accuracy: 0.9892\n",
            "Epoch 60/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9960\n",
            "Epoch 00060: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0111 - accuracy: 0.9959 - val_loss: 0.0475 - val_accuracy: 0.9907\n",
            "Epoch 61/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9959\n",
            "Epoch 00061: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0472 - val_accuracy: 0.9906\n",
            "Epoch 62/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9962\n",
            "Epoch 00062: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 0.0446 - val_accuracy: 0.9908\n",
            "Epoch 63/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9963\n",
            "Epoch 00063: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0468 - val_accuracy: 0.9907\n",
            "Epoch 64/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9962\n",
            "Epoch 00064: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0517 - val_accuracy: 0.9897\n",
            "Epoch 65/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9964\n",
            "Epoch 00065: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0471 - val_accuracy: 0.9904\n",
            "Epoch 66/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9967\n",
            "Epoch 00066: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0475 - val_accuracy: 0.9900\n",
            "Epoch 67/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9964\n",
            "Epoch 00067: loss did not improve from 0.00994\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.0469 - val_accuracy: 0.9908\n",
            "Epoch 68/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
            "Epoch 00068: loss improved from 0.00994 to 0.00750, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0471 - val_accuracy: 0.9911\n",
            "Epoch 69/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
            "Epoch 00069: loss improved from 0.00750 to 0.00699, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0475 - val_accuracy: 0.9911\n",
            "Epoch 70/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
            "Epoch 00070: loss improved from 0.00699 to 0.00698, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0466 - val_accuracy: 0.9905\n",
            "Epoch 71/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
            "Epoch 00071: loss improved from 0.00698 to 0.00612, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0468 - val_accuracy: 0.9906\n",
            "Epoch 72/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9976\n",
            "Epoch 00072: loss did not improve from 0.00612\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0458 - val_accuracy: 0.9908\n",
            "Epoch 73/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
            "Epoch 00073: loss did not improve from 0.00612\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0450 - val_accuracy: 0.9906\n",
            "Epoch 74/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
            "Epoch 00074: loss improved from 0.00612 to 0.00578, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0461 - val_accuracy: 0.9909\n",
            "Epoch 75/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
            "Epoch 00075: loss improved from 0.00578 to 0.00577, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0455 - val_accuracy: 0.9911\n",
            "Epoch 76/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
            "Epoch 00076: loss did not improve from 0.00577\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0458 - val_accuracy: 0.9906\n",
            "Epoch 77/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
            "Epoch 00077: loss did not improve from 0.00577\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0459 - val_accuracy: 0.9910\n",
            "Epoch 78/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9981\n",
            "Epoch 00078: loss improved from 0.00577 to 0.00555, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0460 - val_accuracy: 0.9911\n",
            "Epoch 79/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n",
            "Epoch 00079: loss improved from 0.00555 to 0.00530, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0473 - val_accuracy: 0.9905\n",
            "Epoch 80/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 00080: loss did not improve from 0.00530\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0485 - val_accuracy: 0.9905\n",
            "Epoch 81/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
            "Epoch 00081: loss did not improve from 0.00530\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0506 - val_accuracy: 0.9904\n",
            "Epoch 82/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 00082: loss improved from 0.00530 to 0.00512, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0480 - val_accuracy: 0.9911\n",
            "Epoch 83/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981\n",
            "Epoch 00083: loss did not improve from 0.00512\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0472 - val_accuracy: 0.9909\n",
            "Epoch 84/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n",
            "Epoch 00084: loss improved from 0.00512 to 0.00435, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0470 - val_accuracy: 0.9909\n",
            "Epoch 85/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9985\n",
            "Epoch 00085: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0459 - val_accuracy: 0.9916\n",
            "Epoch 86/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
            "Epoch 00086: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0459 - val_accuracy: 0.9910\n",
            "Epoch 87/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 00087: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
            "Epoch 88/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9978\n",
            "Epoch 00088: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0055 - accuracy: 0.9979 - val_loss: 0.0475 - val_accuracy: 0.9911\n",
            "Epoch 89/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
            "Epoch 00089: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0479 - val_accuracy: 0.9913\n",
            "Epoch 90/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9982\n",
            "Epoch 00090: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0050 - accuracy: 0.9982 - val_loss: 0.0479 - val_accuracy: 0.9913\n",
            "Epoch 91/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9984\n",
            "Epoch 00091: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
            "Epoch 92/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
            "Epoch 00092: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0462 - val_accuracy: 0.9914\n",
            "Epoch 93/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
            "Epoch 00093: loss did not improve from 0.00435\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
            "Epoch 94/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 00094: loss improved from 0.00435 to 0.00412, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0475 - val_accuracy: 0.9909\n",
            "Epoch 95/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
            "Epoch 00095: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
            "Epoch 96/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
            "Epoch 00096: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0479 - val_accuracy: 0.9911\n",
            "Epoch 97/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9983\n",
            "Epoch 00097: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0484 - val_accuracy: 0.9908\n",
            "Epoch 98/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987\n",
            "Epoch 00098: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0491 - val_accuracy: 0.9906\n",
            "Epoch 99/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9984\n",
            "Epoch 00099: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9984 - val_loss: 0.0488 - val_accuracy: 0.9910\n",
            "Epoch 100/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
            "Epoch 00100: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0493 - val_accuracy: 0.9913\n",
            "Epoch 101/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9984\n",
            "Epoch 00101: loss did not improve from 0.00412\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0494 - val_accuracy: 0.9911\n",
            "Epoch 102/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 00102: loss improved from 0.00412 to 0.00393, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0494 - val_accuracy: 0.9913\n",
            "Epoch 103/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
            "Epoch 00103: loss did not improve from 0.00393\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
            "Epoch 104/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 00104: loss did not improve from 0.00393\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
            "Epoch 105/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9984\n",
            "Epoch 00105: loss did not improve from 0.00393\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0481 - val_accuracy: 0.9912\n",
            "Epoch 106/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n",
            "Epoch 00106: loss improved from 0.00393 to 0.00389, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0498 - val_accuracy: 0.9911\n",
            "Epoch 107/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n",
            "Epoch 00107: loss improved from 0.00389 to 0.00349, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0508 - val_accuracy: 0.9912\n",
            "Epoch 108/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
            "Epoch 00108: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0495 - val_accuracy: 0.9912\n",
            "Epoch 109/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
            "Epoch 00109: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0497 - val_accuracy: 0.9909\n",
            "Epoch 110/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
            "Epoch 00110: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0473 - val_accuracy: 0.9914\n",
            "Epoch 111/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
            "Epoch 00111: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0499 - val_accuracy: 0.9913\n",
            "Epoch 112/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
            "Epoch 00112: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0506 - val_accuracy: 0.9911\n",
            "Epoch 113/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 00113: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0511 - val_accuracy: 0.9908\n",
            "Epoch 114/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 00114: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0501 - val_accuracy: 0.9911\n",
            "Epoch 115/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 00115: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0529 - val_accuracy: 0.9911\n",
            "Epoch 116/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
            "Epoch 00116: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0508 - val_accuracy: 0.9910\n",
            "Epoch 117/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
            "Epoch 00117: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0496 - val_accuracy: 0.9912\n",
            "Epoch 118/300\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
            "Epoch 00118: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0499 - val_accuracy: 0.9911\n",
            "Epoch 119/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
            "Epoch 00119: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0509 - val_accuracy: 0.9910\n",
            "Epoch 120/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
            "Epoch 00120: loss did not improve from 0.00349\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0492 - val_accuracy: 0.9913\n",
            "Epoch 121/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00121: loss improved from 0.00349 to 0.00313, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0500 - val_accuracy: 0.9912\n",
            "Epoch 122/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
            "Epoch 00122: loss did not improve from 0.00313\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0491 - val_accuracy: 0.9915\n",
            "Epoch 123/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
            "Epoch 00123: loss did not improve from 0.00313\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0492 - val_accuracy: 0.9913\n",
            "Epoch 124/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00124: loss improved from 0.00313 to 0.00310, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0514 - val_accuracy: 0.9911\n",
            "Epoch 125/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00125: loss did not improve from 0.00310\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0505 - val_accuracy: 0.9912\n",
            "Epoch 126/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9988\n",
            "Epoch 00126: loss did not improve from 0.00310\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0506 - val_accuracy: 0.9917\n",
            "Epoch 127/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 00127: loss did not improve from 0.00310\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0504 - val_accuracy: 0.9915\n",
            "Epoch 128/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
            "Epoch 00128: loss improved from 0.00310 to 0.00309, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0513 - val_accuracy: 0.9914\n",
            "Epoch 129/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 00129: loss did not improve from 0.00309\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0514 - val_accuracy: 0.9912\n",
            "Epoch 130/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00130: loss improved from 0.00309 to 0.00305, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0506 - val_accuracy: 0.9914\n",
            "Epoch 131/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
            "Epoch 00131: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0515 - val_accuracy: 0.9911\n",
            "Epoch 132/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00132: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0516 - val_accuracy: 0.9912\n",
            "Epoch 133/300\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 00133: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0526 - val_accuracy: 0.9910\n",
            "Epoch 134/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
            "Epoch 00134: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0525 - val_accuracy: 0.9909\n",
            "Epoch 135/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9987\n",
            "Epoch 00135: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0516 - val_accuracy: 0.9910\n",
            "Epoch 136/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
            "Epoch 00136: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0528 - val_accuracy: 0.9910\n",
            "Epoch 137/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 00137: loss did not improve from 0.00305\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0512 - val_accuracy: 0.9906\n",
            "Epoch 138/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 00138: loss improved from 0.00305 to 0.00301, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0519 - val_accuracy: 0.9911\n",
            "Epoch 139/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00139: loss improved from 0.00301 to 0.00298, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0536 - val_accuracy: 0.9910\n",
            "Epoch 140/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00140: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0520 - val_accuracy: 0.9910\n",
            "Epoch 141/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
            "Epoch 00141: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0516 - val_accuracy: 0.9911\n",
            "Epoch 142/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9987\n",
            "Epoch 00142: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0510 - val_accuracy: 0.9910\n",
            "Epoch 143/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00143: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0513 - val_accuracy: 0.9907\n",
            "Epoch 144/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00144: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0533 - val_accuracy: 0.9910\n",
            "Epoch 145/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 00145: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0530 - val_accuracy: 0.9910\n",
            "Epoch 146/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00146: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0533 - val_accuracy: 0.9912\n",
            "Epoch 147/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
            "Epoch 00147: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0522 - val_accuracy: 0.9912\n",
            "Epoch 148/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 00148: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0513 - val_accuracy: 0.9917\n",
            "Epoch 149/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
            "Epoch 00149: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0502 - val_accuracy: 0.9912\n",
            "Epoch 150/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 00150: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0512 - val_accuracy: 0.9913\n",
            "Epoch 151/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n",
            "Epoch 00151: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0514 - val_accuracy: 0.9913\n",
            "Epoch 152/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00152: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0510 - val_accuracy: 0.9916\n",
            "Epoch 153/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
            "Epoch 00153: loss did not improve from 0.00298\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0525 - val_accuracy: 0.9910\n",
            "Epoch 154/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00154: loss improved from 0.00298 to 0.00276, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0531 - val_accuracy: 0.9908\n",
            "Epoch 155/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 00155: loss did not improve from 0.00276\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0523 - val_accuracy: 0.9910\n",
            "Epoch 156/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00156: loss did not improve from 0.00276\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0533 - val_accuracy: 0.9910\n",
            "Epoch 157/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9987\n",
            "Epoch 00157: loss did not improve from 0.00276\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 0.0524 - val_accuracy: 0.9911\n",
            "Epoch 158/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n",
            "Epoch 00158: loss did not improve from 0.00276\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0522 - val_accuracy: 0.9913\n",
            "Epoch 159/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 00159: loss did not improve from 0.00276\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0532 - val_accuracy: 0.9913\n",
            "Epoch 160/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00160: loss did not improve from 0.00276\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0526 - val_accuracy: 0.9911\n",
            "Epoch 161/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00161: loss improved from 0.00276 to 0.00272, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0535 - val_accuracy: 0.9912\n",
            "Epoch 162/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00162: loss did not improve from 0.00272\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0538 - val_accuracy: 0.9915\n",
            "Epoch 163/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 00163: loss did not improve from 0.00272\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0530 - val_accuracy: 0.9913\n",
            "Epoch 164/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00164: loss did not improve from 0.00272\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0543 - val_accuracy: 0.9914\n",
            "Epoch 165/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 00165: loss did not improve from 0.00272\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0510 - val_accuracy: 0.9912\n",
            "Epoch 166/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
            "Epoch 00166: loss improved from 0.00272 to 0.00263, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0518 - val_accuracy: 0.9914\n",
            "Epoch 167/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00167: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0536 - val_accuracy: 0.9913\n",
            "Epoch 168/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00168: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0529 - val_accuracy: 0.9915\n",
            "Epoch 169/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
            "Epoch 00169: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0534 - val_accuracy: 0.9911\n",
            "Epoch 170/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 00170: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0523 - val_accuracy: 0.9910\n",
            "Epoch 171/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00171: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0536 - val_accuracy: 0.9912\n",
            "Epoch 172/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00172: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0528 - val_accuracy: 0.9910\n",
            "Epoch 173/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00173: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0547 - val_accuracy: 0.9911\n",
            "Epoch 174/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 00174: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0534 - val_accuracy: 0.9911\n",
            "Epoch 175/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 00175: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0529 - val_accuracy: 0.9911\n",
            "Epoch 176/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00176: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0524 - val_accuracy: 0.9910\n",
            "Epoch 177/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00177: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0524 - val_accuracy: 0.9912\n",
            "Epoch 178/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00178: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0535 - val_accuracy: 0.9914\n",
            "Epoch 179/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
            "Epoch 00179: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0541 - val_accuracy: 0.9912\n",
            "Epoch 180/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
            "Epoch 00180: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0534 - val_accuracy: 0.9912\n",
            "Epoch 181/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00181: loss improved from 0.00263 to 0.00263, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0537 - val_accuracy: 0.9913\n",
            "Epoch 182/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
            "Epoch 00182: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0527 - val_accuracy: 0.9914\n",
            "Epoch 183/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 00183: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0527 - val_accuracy: 0.9913\n",
            "Epoch 184/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00184: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0536 - val_accuracy: 0.9912\n",
            "Epoch 185/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00185: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0536 - val_accuracy: 0.9913\n",
            "Epoch 186/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00186: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0548 - val_accuracy: 0.9911\n",
            "Epoch 187/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 00187: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0551 - val_accuracy: 0.9911\n",
            "Epoch 188/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
            "Epoch 00188: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0548 - val_accuracy: 0.9910\n",
            "Epoch 189/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00189: loss did not improve from 0.00263\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0550 - val_accuracy: 0.9909\n",
            "Epoch 190/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
            "Epoch 00190: loss improved from 0.00263 to 0.00249, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0551 - val_accuracy: 0.9908\n",
            "Epoch 191/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
            "Epoch 00191: loss improved from 0.00249 to 0.00232, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0562 - val_accuracy: 0.9909\n",
            "Epoch 192/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00192: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0549 - val_accuracy: 0.9911\n",
            "Epoch 193/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
            "Epoch 00193: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0546 - val_accuracy: 0.9908\n",
            "Epoch 194/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00194: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0532 - val_accuracy: 0.9910\n",
            "Epoch 195/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 00195: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0549 - val_accuracy: 0.9910\n",
            "Epoch 196/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 00196: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0568 - val_accuracy: 0.9912\n",
            "Epoch 197/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00197: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0551 - val_accuracy: 0.9911\n",
            "Epoch 198/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
            "Epoch 00198: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0562 - val_accuracy: 0.9910\n",
            "Epoch 199/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 00199: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0561 - val_accuracy: 0.9911\n",
            "Epoch 200/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 00200: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0549 - val_accuracy: 0.9911\n",
            "Epoch 201/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 00201: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0540 - val_accuracy: 0.9907\n",
            "Epoch 202/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9989\n",
            "Epoch 00202: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0546 - val_accuracy: 0.9908\n",
            "Epoch 203/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00203: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0541 - val_accuracy: 0.9909\n",
            "Epoch 204/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00204: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0541 - val_accuracy: 0.9912\n",
            "Epoch 205/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 00205: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0557 - val_accuracy: 0.9915\n",
            "Epoch 206/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00206: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0548 - val_accuracy: 0.9916\n",
            "Epoch 207/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
            "Epoch 00207: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0542 - val_accuracy: 0.9912\n",
            "Epoch 208/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
            "Epoch 00208: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0536 - val_accuracy: 0.9913\n",
            "Epoch 209/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 00209: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0542 - val_accuracy: 0.9914\n",
            "Epoch 210/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
            "Epoch 00210: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0546 - val_accuracy: 0.9912\n",
            "Epoch 211/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9988\n",
            "Epoch 00211: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.0547 - val_accuracy: 0.9911\n",
            "Epoch 212/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 00212: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0551 - val_accuracy: 0.9908\n",
            "Epoch 213/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
            "Epoch 00213: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0557 - val_accuracy: 0.9908\n",
            "Epoch 214/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00214: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0543 - val_accuracy: 0.9910\n",
            "Epoch 215/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00215: loss did not improve from 0.00232\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0562 - val_accuracy: 0.9910\n",
            "Epoch 216/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
            "Epoch 00216: loss improved from 0.00232 to 0.00212, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0572 - val_accuracy: 0.9907\n",
            "Epoch 217/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
            "Epoch 00217: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0552 - val_accuracy: 0.9910\n",
            "Epoch 218/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9988\n",
            "Epoch 00218: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0551 - val_accuracy: 0.9913\n",
            "Epoch 219/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 00219: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0543 - val_accuracy: 0.9909\n",
            "Epoch 220/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00220: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0543 - val_accuracy: 0.9911\n",
            "Epoch 221/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00221: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0546 - val_accuracy: 0.9909\n",
            "Epoch 222/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00222: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0546 - val_accuracy: 0.9908\n",
            "Epoch 223/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
            "Epoch 00223: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0548 - val_accuracy: 0.9911\n",
            "Epoch 224/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00224: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0550 - val_accuracy: 0.9913\n",
            "Epoch 225/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
            "Epoch 00225: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0563 - val_accuracy: 0.9910\n",
            "Epoch 226/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
            "Epoch 00226: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0558 - val_accuracy: 0.9912\n",
            "Epoch 227/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00227: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0571 - val_accuracy: 0.9911\n",
            "Epoch 228/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 00228: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0541 - val_accuracy: 0.9910\n",
            "Epoch 229/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 00229: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0549 - val_accuracy: 0.9915\n",
            "Epoch 230/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00230: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0545 - val_accuracy: 0.9914\n",
            "Epoch 231/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 00231: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0542 - val_accuracy: 0.9914\n",
            "Epoch 232/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00232: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0556 - val_accuracy: 0.9911\n",
            "Epoch 233/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
            "Epoch 00233: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0551 - val_accuracy: 0.9911\n",
            "Epoch 234/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 00234: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0547 - val_accuracy: 0.9909\n",
            "Epoch 235/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 00235: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0556 - val_accuracy: 0.9906\n",
            "Epoch 236/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
            "Epoch 00236: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0570 - val_accuracy: 0.9909\n",
            "Epoch 237/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00237: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0553 - val_accuracy: 0.9906\n",
            "Epoch 238/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 00238: loss did not improve from 0.00212\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0566 - val_accuracy: 0.9908\n",
            "Epoch 239/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\n",
            "Epoch 00239: loss improved from 0.00212 to 0.00200, saving model to MNIST_Model.iv3.hdf5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0560 - val_accuracy: 0.9908\n",
            "Epoch 240/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 00240: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0560 - val_accuracy: 0.9908\n",
            "Epoch 241/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\n",
            "Epoch 00241: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0544 - val_accuracy: 0.9911\n",
            "Epoch 242/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
            "Epoch 00242: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0544 - val_accuracy: 0.9910\n",
            "Epoch 243/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 00243: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0552 - val_accuracy: 0.9906\n",
            "Epoch 244/300\n",
            "466/469 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 00244: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0548 - val_accuracy: 0.9907\n",
            "Epoch 245/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00245: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0563 - val_accuracy: 0.9906\n",
            "Epoch 246/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00246: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0565 - val_accuracy: 0.9906\n",
            "Epoch 247/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 00247: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0564 - val_accuracy: 0.9911\n",
            "Epoch 248/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00248: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0564 - val_accuracy: 0.9914\n",
            "Epoch 249/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 00249: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0550 - val_accuracy: 0.9914\n",
            "Epoch 250/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
            "Epoch 00250: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0533 - val_accuracy: 0.9914\n",
            "Epoch 251/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 00251: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0544 - val_accuracy: 0.9911\n",
            "Epoch 252/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 00252: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0544 - val_accuracy: 0.9912\n",
            "Epoch 253/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
            "Epoch 00253: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0557 - val_accuracy: 0.9909\n",
            "Epoch 254/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
            "Epoch 00254: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0564 - val_accuracy: 0.9913\n",
            "Epoch 255/300\n",
            "465/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00255: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0566 - val_accuracy: 0.9913\n",
            "Epoch 256/300\n",
            "464/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 00256: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0561 - val_accuracy: 0.9910\n",
            "Epoch 257/300\n",
            "461/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 00257: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0552 - val_accuracy: 0.9914\n",
            "Epoch 258/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00258: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0569 - val_accuracy: 0.9910\n",
            "Epoch 259/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993\n",
            "Epoch 00259: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0576 - val_accuracy: 0.9913\n",
            "Epoch 260/300\n",
            "467/469 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 00260: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0562 - val_accuracy: 0.9914\n",
            "Epoch 261/300\n",
            "459/469 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
            "Epoch 00261: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0569 - val_accuracy: 0.9911\n",
            "Epoch 262/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 00262: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0581 - val_accuracy: 0.9907\n",
            "Epoch 263/300\n",
            "460/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
            "Epoch 00263: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0565 - val_accuracy: 0.9910\n",
            "Epoch 264/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 00264: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0569 - val_accuracy: 0.9910\n",
            "Epoch 265/300\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
            "Epoch 00265: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0574 - val_accuracy: 0.9909\n",
            "Epoch 266/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9992\n",
            "Epoch 00266: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0580 - val_accuracy: 0.9911\n",
            "Epoch 267/300\n",
            "463/469 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
            "Epoch 00267: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0580 - val_accuracy: 0.9909\n",
            "Epoch 268/300\n",
            "462/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9991\n",
            "Epoch 00268: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0577 - val_accuracy: 0.9908\n",
            "Epoch 269/300\n",
            "468/469 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 00269: loss did not improve from 0.00200\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0582 - val_accuracy: 0.9909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5b826196a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkd-bsKL3Jzi"
      },
      "source": [
        "Com a rede treinada, vamos usar o dataset de testes para extrair os dados para análise quantitativa da performance da rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-Nl_yxx3JlR",
        "outputId": "22ffc2e7-6598-46ab-d9e3-4733340a50c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "result = cnn.evaluate(test_dataset, test_classes)\n",
        "print ('Accuracy = ' + str(result[1] * 100) + \"%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9909\n",
            "Accuracy = 99.08999800682068%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFaUEbFZt5h9"
      },
      "source": [
        "# Analise da qualidade do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWWJW6got8yi",
        "outputId": "f63e6fce-8094-469e-bd0b-62c62fcebb70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        }
      },
      "source": [
        "# Confusion Matrix stuff\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10)) # Set Figure\n",
        "\n",
        "y_pred = cnn.predict(test_dataset)\n",
        "\n",
        "Y_pred = np.argmax(y_pred, 1) # Decode Predicted labels\n",
        "Y_test = np.argmax(test_classes, 1) # Decode labels\n",
        "\n",
        "mat = confusion_matrix(Y_test, Y_pred) # Confusion matrix\n",
        "\n",
        "# Plot Confusion matrix\n",
        "sns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues)\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('True Values');\n",
        "plt.show();\n",
        "\n",
        "print(\"Accuracy {0:.2f}%\".format(100*accuracy_score(Y_pred, Y_test)))\n",
        "\n",
        "print(classification_report(Y_test, Y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy 99.09%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.99      1.00      0.99      1010\n",
            "           4       0.99      0.99      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      0.99      0.99       974\n",
            "           9       0.99      0.98      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}